apiVersion: llamastack.io/v1alpha1
kind: LlamaStackDistribution
metadata:
  name: llamastack
spec:
  replicas: 1
  server:
    containerSpec:
      env:
        - name: MAX_TOKENS
          value: '128000'
        - name: VLLM_MAX_TOKENS
          value: '128000'
        - name: INFERENCE_MODEL
          value: llama32-3b
        - name: GRANITE_URL
          value: 'http://granite32-8b-predictor:8080/v1'
        - name: GRANITE_MODEL
          value: granite32-8b
        - name: LLAMA3B_URL
          value: 'http://llama32-3b-predictor:8080/v1'
        - name: GRANITE_VLLM_API_TOKEN
          value: fake
        - name: LLAMA_VLLM_API_TOKEN
          value: fake
        - name: MILVUS_DB_PATH
          value: milvus.db
        - name: LLAMA_STACK_LOG
          value: debug
        - name: OTEL_SERVICE_NAME
          value: llamastack
        - name: FMS_ORCHESTRATOR_URL
          value: http://localhost:8080
      name: llama-stack
      port: 8321
    distribution:
      name: rh-dev
    userConfig:
      configMapName: llama-stack-config